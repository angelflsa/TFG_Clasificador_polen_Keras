{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vgg16 entrenada en spyder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del modelo entrenado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra el código de la cnn entrenada, basándose en la red pre-entrenada vgg16, congelando todas las capas excepto la top layer incluida para distinguir entre tres clases diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers import  Convolution2D, MaxPooling2D, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "\n",
    "K.clear_session()\n",
    "np.random.seed(0)\n",
    "\n",
    "def modelo():\n",
    "    vgg=applications.vgg16.VGG16()\n",
    "    cnn=Sequential()\n",
    "    for capa in vgg.layers:\n",
    "        cnn.add(capa)\n",
    "    cnn.layers.pop()\n",
    "    for layer in cnn.layers:\n",
    "        layer.trainable=False\n",
    "    cnn.add(Dense(3,activation='softmax'))\n",
    "    return cnn\n",
    "\n",
    "#Se almacenan en variables los directorios en los que se encuentran las imágenes\n",
    "data_entrenamiento = './data/entrenamiento'\n",
    "data_validacion = './data/validacion'\n",
    "\n",
    "#Parámetros importantes:\n",
    "epocas=20\n",
    "longitud, altura = 224, 224\n",
    "batch_size = 32 #Imágenes a procesar en cada paso\n",
    "pasos = 100\n",
    "validation_steps = 100 #Imágenes de validación que se pasan al final de cada época\n",
    "clases = 3\n",
    "lr = 0.0004 #Learning rate\n",
    "\n",
    "###Procesamiento del conjunto de entrenamieto:\n",
    "#Se aplican mecanismos de data argumentation\n",
    "entrenamiento_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255, \n",
    "    shear_range=0.2, #Inclina las imágenes\n",
    "    zoom_range=0.2, #Zoom a algunas imágenes\n",
    "    horizontal_flip=True) #Invierte imágenes para distinguir direcionalidad\n",
    "\n",
    "###Procesamiento del conjunto de validación:\n",
    "#No es necesario inclinar, hacer zoom ni invertir las imágenes.\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "###Generación del conjunto de entrenamieto:\n",
    "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
    "    data_entrenamiento,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical') #Se busca una clasificación categórica\n",
    "\n",
    "###Generación del conjunto de validación:\n",
    "validacion_generador = test_datagen.flow_from_directory(\n",
    "    data_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model=modelo()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(lr=lr),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    entrenamiento_generador,\n",
    "    steps_per_epoch=pasos,\n",
    "    epochs=epocas,\n",
    "    validation_data=validacion_generador,\n",
    "    validation_steps=validation_steps)\n",
    "\n",
    "print(entrenamiento_generador.class_indices)\n",
    "\n",
    "#score = model.evaluate_generator(validacion_generador, steps=20, verbose=1)\n",
    "#print('Test accuracy:', score[1])\n",
    "\n",
    "dir = './vgg16_largo/'\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "model.save('./vgg16_largo/modelo_vgg16_largo.h5')#Se guarda la estructura de la cnn\n",
    "model.save_weights('./vgg16_largo/pesos_vgg16_largo.h5')#Se guardan los pesos de la cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura y pesos de esto modelo han sido guardados en el directorio './vgg16_largo/'. Se cargan la red para realizar predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 17 layers into a model with 0 layers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b5be734b6d4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcarga_modelo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./vgg16_largo/modelo_vgg16_largo.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpesos_modelo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./vgg16_largo/pesos_vgg16_largo.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarga_modelo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpesos_modelo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Angel\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Angel\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[1;34m(f, custom_objects, compile)\u001b[0m\n\u001b[0;32m    256\u001b[0m         raise ValueError('You are trying to load a weight file'\n\u001b[0;32m    257\u001b[0m                          \u001b[1;34m' containing {} layers into a model with {} layers'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m                          \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m                          )\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 17 layers into a model with 0 layers"
     ]
    }
   ],
   "source": [
    "carga_modelo = './vgg16_largo/modelo_vgg16_largo.h5'\n",
    "pesos_modelo = './vgg16_largo/pesos_vgg16_largo.h5'\n",
    "cnn = load_model(carga_modelo)\n",
    "cnn.load_weights(pesos_modelo)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueba generando la arquitectura de la red de nuevo y cargar los pesos guardados en el directorio './vgg16_largo/pesos_vgg16_largo.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Angel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "vgg=applications.vgg16.VGG16()\n",
    "cnn=Sequential()\n",
    "for capa in vgg.layers:\n",
    "    cnn.add(capa)\n",
    "cnn.layers.pop()\n",
    "for layer in cnn.layers:\n",
    "    layer.trainable=False\n",
    "cnn.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3003      \n",
      "=================================================================\n",
      "Total params: 138,360,547\n",
      "Trainable params: 3,003\n",
      "Non-trainable params: 138,357,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si, cargamos los pesos obtenidos con el entrenamiento previo de la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos_modelo = './vgg16_largo/pesos_vgg16_largo.h5'\n",
    "cnn.load_weights(pesos_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados entrenamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluando el modelo se obtubieron los siguientes resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validacion_generador, steps=pasos, verbose=1)\n",
    "print('Test accuracy:', score[1])\n",
    "print('Loss:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100/100 [==============================] - 2023s 20s/step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy: 0.5018808776121528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss: 0.7800169631978935"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: para conocer el índice que se corresponde con cada clase, se usa el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entrenamiento_generador.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'gato': 0, 'gorila': 1, 'perro': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades: [[0.4848556  0.07351075 0.44163367]]\n",
      "0\n",
      "pred: Gato\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Función predicción:\n",
    "def predict(file):\n",
    "  x = load_img(file, target_size=(224, 224))\n",
    "  x = img_to_array(x)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  array = cnn.predict(x)\n",
    "  print('Probabilidades:', array)  \n",
    "  result = array[0]\n",
    "  answer = np.argmax(result) #Devuelve el índice en el que se encuentra el valor máximo\n",
    "  print(answer)  \n",
    "  if answer == 0:\n",
    "    print(\"pred: Gato\")\n",
    "  elif answer == 1:\n",
    "    print(\"pred: Gorila\")\n",
    "  elif answer == 2:\n",
    "    print(\"pred: Perro\")\n",
    "  return answer\n",
    "\n",
    "predict('cat.4.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso, se cumple la predicción, y la imagen 'cat.4.jpg' efectivamente es un gato. En cambio si realizamos más predicciones vemos como muchas no son correctas, poniéndose de manifiesto el porcentaje de acierto (Test accuracy: 0.5018808776121528) obtenido en la evaluación del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
